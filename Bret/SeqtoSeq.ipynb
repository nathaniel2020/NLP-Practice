{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 定义超参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "time_steps = 5 # 时间步\n",
    "n_hidden = 128 # RNN隐藏层大小\n",
    "EPOCH = 5000\n",
    "epoch_print = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 加载数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "datas = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "char_list = [chr(i) for i in range(ord('a'), ord('a') + 26)]\n",
    "char_list.extend(list('SEP'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# 字符与index对应\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_list)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "n_classes = len(char_to_idx)\n",
    "batch_size = len(datas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def make_batch(datas):\n",
    "    # encode的输入, decoder的输入, 目标结果\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "    # 填充较短的单词（句子）\n",
    "    for data in datas:\n",
    "        for i in range(2):\n",
    "            data[i] += 'P' * (time_steps - len(data[i]))\n",
    "\n",
    "        # char转index\n",
    "        input = [char_to_idx[char] for char in data[0]]\n",
    "        # output 作为decoder的输入，添加标记符号S，作为其开始\n",
    "        output = [char_to_idx[char] for char in ('S' + data[1])]\n",
    "        target = [char_to_idx[char] for char in (data[1] + 'E')]\n",
    "\n",
    "        # 转化为tensor，并加入batch\n",
    "        # F.one_hot返回的张量\n",
    "        #   size: (time_steps, n_classes)\n",
    "        #   type: torch.LongTensor\n",
    "        input_batch.append(F.one_hot(torch.tensor(input), n_classes))\n",
    "        output_batch.append(F.one_hot(torch.tensor(output), n_classes))\n",
    "        target_batch.append(torch.LongTensor(target))\n",
    "\n",
    "    # 将列表（其中元素为tensor）整合为一个tensor\n",
    "    # batch:\n",
    "    #   size: (batch_size, time_steps, n_classes)\n",
    "    #   type: torch.FloatTensor\n",
    "    return (torch.stack(input_batch, dim=0).float(),\n",
    "            torch.stack(output_batch, dim=0).float(),\n",
    "            torch.stack(target_batch, dim=0).float())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(datas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "class SeqToSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SeqToSeq, self).__init__()\n",
    "\n",
    "        # 第一维为batch_size\n",
    "        self.encoder = nn.RNN(input_size=n_classes, hidden_size=n_hidden, dropout=0.5, batch_first=True)\n",
    "        self.decoder = nn.RNN(input_size=n_classes, hidden_size=n_hidden, dropout=0.5, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        '''\n",
    "\n",
    "        :param enc_input: size: (batch_size, time_steps, n_classes)\n",
    "        :param enc_hidden: size: (num_layers * num_directions, batch_size, n_hidden)\n",
    "        :param dec_input: size: (batch_size, time_steps + 1, n_classes) 解码器的输入多了一个开始符号S\n",
    "        :return:\n",
    "        '''\n",
    "        # _ size: (batch_size, time_steps, num_directions(=1) * n_hidden(=128))\n",
    "        # enc_state: (batch_size, num_layers(=1) * num_directions(=1), n_hidden)\n",
    "        _, enc_state = self.encoder(enc_input, enc_hidden)\n",
    "        # outputs size: (batch_size, time_steps + 1, num_directions(=1) * n_hidden(=128))\n",
    "        # _ size: (batch_size, num_layers(=1) * num_directions(=1), n_hidden)\n",
    "        outputs, _ = self.decoder(dec_input, enc_state)\n",
    "        outputs = self.fc(outputs) # size: (batch_size, time_steps + 1, n_classes)\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr = 0.001\n",
    "model = SeqToSeq()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 114,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathaniel/miniforge3/envs/learn/lib/python3.9/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1000 Loss = 0.003916\n",
      "Epoch = 2000 Loss = 0.001048\n",
      "Epoch = 3000 Loss = 0.000442\n",
      "Epoch = 4000 Loss = 0.000220\n",
      "Epoch = 5000 Loss = 0.000118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCH):\n",
    "    hidden = torch.zeros(1,batch_size, n_hidden)\n",
    "    # print(input_batch.type(), hidden.type(), output_batch.type())\n",
    "    outputs = model(input_batch, hidden, output_batch) # size: (batch_size, time_steps + 1, n_classes)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = 0\n",
    "    for i in range(outputs.size()[0]):\n",
    "        #print(outputs[i].type(), target_batch[i].type())\n",
    "        loss += criterion(outputs[i], target_batch[i].long())\n",
    "\n",
    "    if (epoch + 1) % epoch_print == 0:\n",
    "        print('Epoch = %d Loss = %.6f'%(epoch + 1, loss))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "def make_test_batch(word):\n",
    "    input_batch, output_batch = [], []\n",
    "    input_word = word + 'P' * (time_steps - len(word))\n",
    "    input = [char_to_idx[char] for char in input_word]\n",
    "    output = [char_to_idx[char] for char in 'S' + 'P' * time_steps]\n",
    "\n",
    "    input_batch.append(F.one_hot(torch.tensor(input), n_classes))\n",
    "    output_batch.append(F.one_hot(torch.tensor(output), n_classes))\n",
    "\n",
    "    return (\n",
    "        torch.stack(input_batch, dim=0).float(),\n",
    "        torch.stack(output_batch, dim=0).float(),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    input_batch, output_batch = make_test_batch(word)\n",
    "    # 因为一个单词, batch_size=1\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "\n",
    "    # size: (batch_size=1, time_steps+1, n_classes)\n",
    "    outputs = model(input_batch, hidden, output_batch)\n",
    "    # 取最大值的index\n",
    "    # squeeze 把batch_size那一维去掉\n",
    "    predicts = torch.argmax(outputs.squeeze(), dim=1).numpy().tolist()\n",
    "\n",
    "    predict_word = ''.join([idx_to_char[idx] for idx in predicts])\n",
    "    # 去除E, P标记\n",
    "    predict_word = predict_word.replace('P', '').replace('E', '')\n",
    "    return predict_word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "man -> women\n",
      "mans -> women\n",
      "king -> queen\n",
      "black -> white\n",
      "upp -> down\n"
     ]
    }
   ],
   "source": [
    "print('test')\n",
    "print('man ->', translate('man'))\n",
    "print('mans ->', translate('mans'))\n",
    "print('king ->', translate('king'))\n",
    "print('black ->', translate('black'))\n",
    "print('upp ->', translate('upp'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd02711a54dea012f70b73017de45182aad7b3e682bea1e9ba96b72ce1a06369155",
   "language": "python",
   "display_name": "Python 3.9.2 64-bit ('learn': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}